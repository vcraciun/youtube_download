To understand how certain health issues can be overcome, researchers conduct experiments on zebrafish. This is possible due to the high similarity between the human genome and that of this species. These trials enable comparisons of behaviors among healthy, ill, and cured subjects. Researchers often discover a new drug when the behaviors of healthy and cured subjects match or exhibit a high similarity rate. However, researchers encounter challenges such as unsuitable environments for analysis instruments, time-consuming analysis procedures, and expensive technology. To assist researchers in improving their efforts to understand their subjects' behaviors, we developed FARM (Framework for Activity Real-time Monitoring). This tool automatically detects the scenario configuration (3D or 2D bidimensional) and processes video recordings in real-time. Additionally, it attempts to describe the behavior to facilitate comparing across a wide range of actions. In this research, we propose a potential solution to translate visual movement specifications (e.g., heatmaps, tracking, speed, position, etc.) into a set of words. We also strive to identify rules for measuring the distance between various behaviors in a dataset consisting of over 300 video recordings.
